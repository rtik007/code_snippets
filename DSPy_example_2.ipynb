{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d82d2e-ad41-48d0-8456-aab08859b9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd303d-b47a-4acd-a634-f552f0b2173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Structured-output DSPy example (Compelling Evidence) — end to end.\n",
    "\n",
    "# %%capture\n",
    "%pip install -q dspy-ai pandas numpy tqdm scikit-learn\n",
    "\n",
    "import os, re, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "INPUT_CSV  = \"training_examples_compelling.csv\"   # <- use the file I created for you\n",
    "OUT_PROMPT = \"improved_prompts_compelling.csv\"\n",
    "OUT_PREDS  = \"tuned_predictions_compelling.csv\"\n",
    "\n",
    "# Choose model/provider you have keys for:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  # uncomment & set if needed\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # change to what you use\n",
    "\n",
    "random.seed(7); np.random.seed(7)\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD DATA\n",
    "# -----------------------------\n",
    "df = pd.read_csv(INPUT_CSV).fillna(\"\")\n",
    "need = {\"initial_prompt\", \"merchant_document_text\", \"is_compelling\", \"confidence_score\", \"evidence_details\"}\n",
    "missing = need - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV must include columns: {sorted(need)}; missing: {sorted(missing)}\")\n",
    "\n",
    "# Ensure types\n",
    "df[\"is_compelling\"] = df[\"is_compelling\"].astype(bool)\n",
    "df[\"confidence_score\"] = df[\"confidence_score\"].astype(float)\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURE DSPy\n",
    "# -----------------------------\n",
    "# Example: OpenAI via dspy.OpenAI; swap to your preferred client if needed.\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    lm = dspy.OpenAI(model=MODEL, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "else:\n",
    "    # You can replace with another client, e.g. dspy.LM(\"ollama/llama3\") if you run locally.\n",
    "    raise RuntimeError(\"Please set OPENAI_API_KEY or swap in a different dspy LM client.\")\n",
    "\n",
    "dspy.configure(lm=lm, temperature=0.2, max_tokens=600)\n",
    "\n",
    "# -----------------------------\n",
    "# SIGNATURE (matches your screenshot)\n",
    "# -----------------------------\n",
    "class PhotoEmailEvidenceSignature(dspy.Signature):\n",
    "    \"\"\"Does the merchant data provide photographic evidence such as a copy of an ID or email correspondence between the merchant and cardholder?\n",
    "    If none of these exist, then the evidence is not compelling.\"\"\"\n",
    "    merchant_document_text = dspy.InputField(desc=\"Extracted text from merchant documents\")\n",
    "    is_compelling = dspy.OutputField(desc=\"Whether photographic or email evidence is found\")\n",
    "    confidence_score = dspy.OutputField(desc=\"Confidence score between 0 and 1\")\n",
    "    evidence_details = dspy.OutputField(desc=\"Specific evidence that was found\")\n",
    "\n",
    "class EvidenceModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.step = dspy.Predict(PhotoEmailEvidenceSignature)\n",
    "    def forward(self, merchant_document_text):\n",
    "        return self.step(merchant_document_text=merchant_document_text)\n",
    "\n",
    "# -----------------------------\n",
    "# HELPERS: convert rows <-> DSPy examples\n",
    "# -----------------------------\n",
    "def make_examples(rows: pd.DataFrame):\n",
    "    exs = []\n",
    "    for _, r in rows.iterrows():\n",
    "        ex = dspy.Example(\n",
    "            merchant_document_text=str(r[\"merchant_document_text\"]),\n",
    "            is_compelling=str(bool(r[\"is_compelling\"])),\n",
    "            confidence_score=str(float(r[\"confidence_score\"])),\n",
    "            evidence_details=str(r[\"evidence_details\"])\n",
    "        ).with_inputs(\"merchant_document_text\")\n",
    "        exs.append(ex)\n",
    "    return exs\n",
    "\n",
    "def parse_bool(x: str):\n",
    "    x = str(x).strip().lower()\n",
    "    return x in {\"true\", \"yes\", \"1\", \"y\", \"t\"}\n",
    "\n",
    "def parse_float(x: str):\n",
    "    s = str(x)\n",
    "    # Try to extract a number from text, fallback to 0.0\n",
    "    m = re.search(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\", s)\n",
    "    try:\n",
    "        return float(m.group(0)) if m else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Metric: average of three components\n",
    "def metric_fn(example, pred, *args):\n",
    "    # Boolean accuracy\n",
    "    gold_bool = parse_bool(example.is_compelling)\n",
    "    pred_bool = parse_bool(getattr(pred, \"is_compelling\", \"\"))\n",
    "    acc = 1.0 if gold_bool == pred_bool else 0.0\n",
    "\n",
    "    # Confidence closeness\n",
    "    gold_c = parse_float(example.confidence_score)\n",
    "    pred_c = max(0.0, min(1.0, parse_float(getattr(pred, \"confidence_score\", \"0\"))))\n",
    "    conf_score = 1.0 - min(1.0, abs(gold_c - pred_c))\n",
    "\n",
    "    # Evidence similarity (F1)\n",
    "    g = set(str(example.evidence_details).lower().split())\n",
    "    p = set(str(getattr(pred, \"evidence_details\", \"\")).lower().split())\n",
    "    inter = len(g & p)\n",
    "    prec = inter / (len(p) + 1e-9)\n",
    "    rec = inter / (len(g) + 1e-9)\n",
    "    f1 = 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "\n",
    "    return 0.4 * acc + 0.3 * conf_score + 0.3 * f1\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN / DEV SPLIT\n",
    "# -----------------------------\n",
    "train_df, dev_df = train_test_split(df, test_size=max(1, len(df)//5), random_state=7, shuffle=True)\n",
    "trainset = make_examples(train_df)\n",
    "devset   = make_examples(dev_df)\n",
    "\n",
    "# -----------------------------\n",
    "# TELEPROMPT (optimize few‑shot)\n",
    "# -----------------------------\n",
    "teleprompter = BootstrapFewShot(metric=metric_fn, max_bootstrapped_demos=6)\n",
    "program = teleprompter.compile(EvidenceModule(), trainset=trainset, valset=devset)\n",
    "\n",
    "# -----------------------------\n",
    "# EXTRACT A HUMAN‑READABLE PROMPT TEMPLATE\n",
    "# -----------------------------\n",
    "def build_prompt_string(teleprompter_obj, program_obj):\n",
    "    instr = PhotoEmailEvidenceSignature.__doc__.strip()\n",
    "    # gather chosen demonstrations if available\n",
    "    demos = (\n",
    "        getattr(teleprompter_obj, \"best_demonstrations_\", None)\n",
    "        or getattr(teleprompter_obj, \"demonstrations_\", None)\n",
    "        or getattr(program_obj, \"demonstrations_\", None)\n",
    "        or []\n",
    "    )\n",
    "    blocks = []\n",
    "    for i, ex in enumerate(demos, 1):\n",
    "        inp = getattr(ex, \"merchant_document_text\", getattr(ex, \"inputs\", {}).get(\"merchant_document_text\", \"\"))\n",
    "        ic = getattr(ex, \"is_compelling\", getattr(ex, \"outputs\", {}).get(\"is_compelling\", \"\"))\n",
    "        cs = getattr(ex, \"confidence_score\", getattr(ex, \"outputs\", {}).get(\"confidence_score\", \"\"))\n",
    "        ed = getattr(ex, \"evidence_details\", getattr(ex, \"outputs\", {}).get(\"evidence_details\", \"\"))\n",
    "        blocks.append(\n",
    "f\"\"\"# Example {i}\n",
    "Merchant document text:\n",
    "{inp}\n",
    "Expected outputs:\n",
    "is_compelling: {ic}\n",
    "confidence_score: {cs}\n",
    "evidence_details: {ed}\"\"\"\n",
    "        )\n",
    "    return (\n",
    "f\"\"\"### Instruction\n",
    "{instr}\n",
    "\n",
    "### Few‑Shot Examples\n",
    "{('\\n\\n'.join(blocks) if blocks else '(teleprompter omitted examples)')}\n",
    "\n",
    "### Now answer for a new case.\n",
    "Merchant document text:\n",
    "{{merchant_document_text}}\n",
    "\n",
    "Return fields:\n",
    "- is_compelling: boolean (True/False)\n",
    "- confidence_score: number between 0 and 1\n",
    "- evidence_details: short phrase describing the specific evidence found\"\"\"\n",
    "    ).strip()\n",
    "\n",
    "improved_prompt = build_prompt_string(teleprompter, program)\n",
    "\n",
    "# -----------------------------\n",
    "# SAVE: improved prompt + a quick dev score\n",
    "# -----------------------------\n",
    "improved_rows = [{\n",
    "    \"task\": \"photo_email_evidence\",\n",
    "    \"improved_prompt\": improved_prompt,\n",
    "    \"n_train\": len(train_df),\n",
    "    \"n_dev\": len(dev_df)\n",
    "}]\n",
    "pd.DataFrame(improved_rows).to_csv(OUT_PROMPT, index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# RUN PREDICTIONS FOR ALL INPUTS\n",
    "# -----------------------------\n",
    "pred_rows = []\n",
    "for _, r in df.iterrows():\n",
    "    pred = program(merchant_document_text=str(r[\"merchant_document_text\"]))\n",
    "    pred_rows.append({\n",
    "        \"merchant_document_text\": r[\"merchant_document_text\"],\n",
    "        \"pred.is_compelling\": getattr(pred, \"is_compelling\", \"\"),\n",
    "        \"pred.confidence_score\": getattr(pred, \"confidence_score\", \"\"),\n",
    "        \"pred.evidence_details\": getattr(pred, \"evidence_details\", \"\"),\n",
    "        \"gold.is_compelling\": str(bool(r[\"is_compelling\"])),\n",
    "        \"gold.confidence_score\": float(r[\"confidence_score\"]),\n",
    "        \"gold.evidence_details\": r[\"evidence_details\"]\n",
    "    })\n",
    "\n",
    "pd.DataFrame(pred_rows).to_csv(OUT_PREDS, index=False)\n",
    "\n",
    "print(\"✅ Done\")\n",
    "print(f\"Saved improved prompt -> {OUT_PROMPT}\")\n",
    "print(f\"Saved predictions    -> {OUT_PREDS}\")\n",
    "\n",
    "# Optional: peek at the prompt\n",
    "print(\"\\n--- Improved Prompt (preview) ---\\n\")\n",
    "print(improved_prompt[:1800] + (\"...\\n[truncated]\" if len(improved_prompt) > 1800 else \"\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

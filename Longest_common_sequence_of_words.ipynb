{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d0e8e-e455-4a67-bab3-e6ce70b7d249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370cb697-bca0-4616-838d-fa90c3462985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f8396b-901c-4f51-ba6d-29cfee95fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    # Lowercase and remove punctuation\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "def longest_common_words(prompt1, prompt2):\n",
    "    words1 = set(preprocess(prompt1))\n",
    "    words2 = set(preprocess(prompt2))\n",
    "    \n",
    "    common_words = words1 & words2  # set intersection\n",
    "    \n",
    "    if not common_words:\n",
    "        return []\n",
    "\n",
    "    max_len = max(len(word) for word in common_words)\n",
    "    return [word for word in common_words if len(word) == max_len]\n",
    "\n",
    "# Example\n",
    "prompt1 = \"The quick brown fox jumped over the lazy dog.\"\n",
    "prompt2 = \"A lazy dog slept under the brown table.\"\n",
    "\n",
    "print(longest_common_words(prompt1, prompt2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070bacc-5d49-4a35-b309-55db48a917ad",
   "metadata": {},
   "source": [
    "## The below code helps to find the longest continuous phrase (not just a single word) that appears in both, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b46520d6-9ea1-441a-81ba-2a673008ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_phrase(prompt1, prompt2):\n",
    "    \"\"\"\n",
    "    Returns the longest contiguous sequence of words present in both prompts.\n",
    "    \"\"\"\n",
    "    words1 = prompt1.split()\n",
    "    words2 = prompt2.split()\n",
    "    len1, len2 = len(words1), len(words2)\n",
    "\n",
    "    # DP table for substring length\n",
    "    dp = [[0]*(len2+1) for _ in range(len1+1)]\n",
    "    maxlen = 0\n",
    "    endpos = 0\n",
    "\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            if words1[i] == words2[j]:\n",
    "                dp[i+1][j+1] = dp[i][j]+1\n",
    "                if dp[i+1][j+1] > maxlen:\n",
    "                    maxlen = dp[i+1][j+1]\n",
    "                    endpos = i+1\n",
    "\n",
    "    if maxlen == 0:\n",
    "        return \"\", 0\n",
    "    return ' '.join(words1[endpos-maxlen:endpos]), maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4cd363b-3277-48c0-b175-7a9dfe4a31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"\n",
    "You are tasked with building a user-friendly, AI-powered application using Generative AI (GenAI) technologies that addresses a real-world need. Your application should use natural language processing (NLP), image generation, or multimodal capabilities to enhance human productivity, creativity, or decision-making. The application must have a clear target audience and a well-defined problem it solves using GenAI.\n",
    "\n",
    "Design an application that leverages the strengths of GenAI to deliver personalized, dynamic, and context-aware experiences. The core functionality should revolve around generating human-like content — such as text, images, summaries, answers, suggestions, or designs — based on user input. Think creatively about how the app can go beyond simple chat-based interactions by integrating GenAI into a full workflow.\n",
    "\n",
    "The application must include the following:\n",
    "\n",
    "Purpose and Use Case: Clearly define the primary goal of the application. What specific problem does it solve? Who is it for? How does GenAI offer a novel or significantly improved solution compared to traditional methods?\n",
    "\n",
    "Key Features: Describe the core features and user interactions. What can users input and expect as output? How is the user interface designed to make GenAI capabilities accessible and useful?\n",
    "\n",
    "GenAI Integration: Explain how GenAI is embedded in the system. Are you using large language models (LLMs) for text generation or summarization? Image generation models like DALL·E or Stable Diffusion? Voice synthesis? Describe the models and APIs used, and how you ensure quality, safety, and relevance in outputs.\n",
    "\n",
    "User Experience and Workflow: Describe how users will interact with the app from start to finish. What makes the experience seamless, efficient, and engaging? How does the app guide users to get the most out of GenAI?\n",
    "\n",
    "Personalization and Context-Awareness: Show how the app uses user data, preferences, or historical context to deliver personalized responses. Can the app adapt to different tones, formats, or content types based on user goals?\n",
    "\n",
    "Ethical and Responsible AI Use: Address how the app avoids hallucinations, bias, or misuse. Does it provide disclaimers, moderation, or feedback mechanisms to ensure GenAI outputs are safe and appropriate?\n",
    "\n",
    "Scalability and Future Enhancements: Outline how the app can grow or expand in future versions. Could it support more languages, integrate additional modalities (e.g., video, audio), or incorporate retrieval-augmented generation (RAG) or memory?\n",
    "\n",
    "You may choose any domain — such as education, healthcare, travel, storytelling, content creation, programming, mental wellness, or business intelligence. The most compelling applications will creatively integrate GenAI while demonstrating an understanding of both the technology's potential and its limitations.\n",
    "\n",
    "Deliver a concept that includes a name for your application, a short user story illustrating how it would be used, and a clear justification for using GenAI over traditional software approaches.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7336e54e-8fe8-43ca-977c-694f7c9e76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"\n",
    "You have been assigned an exciting challenge: to design a user-friendly application that harnesses the power of Generative AI (GenAI) technologies to address a meaningful, real-world problem. Your mission is to build a product that goes beyond traditional software by integrating advanced AI capabilities — such as natural language processing (NLP), image generation, or multimodal functionalities — to significantly enhance human productivity, creativity, or decision-making.\n",
    "\n",
    "The heart of this application lies in its ability to generate human-like content, whether that is text, images, summaries, answers, suggestions, or creative designs. This content is created dynamically based on user input and contextual understanding, offering a personalized and context-aware experience. Unlike simple chatbots or isolated AI features, your application should embed GenAI into a complete workflow that supports users from start to finish, making their interactions intuitive, valuable, and engaging.\n",
    "\n",
    "Purpose and Use Case\n",
    "The first step is to clearly define your application’s core purpose and target audience. What specific problem does the application solve? For whom? This clarity will help focus your design and ensure the app delivers real impact.\n",
    "\n",
    "For example, imagine creating an AI-powered content assistant for freelance writers and marketers. Their challenge is to generate high-quality, engaging content quickly, often under tight deadlines. Traditional tools — like grammar checkers or keyword planners — offer limited support and require manual effort. Your GenAI-based application, however, can provide intelligent writing suggestions, draft outlines, generate creative ideas, and even create accompanying images, all tailored to the user’s style and goals. This novel approach not only saves time but also sparks creativity in ways previously unavailable.\n",
    "\n",
    "The power of GenAI lies in its ability to produce nuanced, contextually relevant outputs that adapt to user needs. Whether it’s summarizing lengthy research into concise key points, generating compelling product descriptions, or producing unique artwork, your application should showcase how AI can transform complex tasks into simple, enjoyable experiences.\n",
    "\n",
    "Key Features and User Interaction\n",
    "To make this vision concrete, define the core features and typical user workflows. What inputs will users provide, and what outputs will they receive? How will the interface facilitate smooth and effective use of GenAI?\n",
    "\n",
    "Continuing with the content assistant example, users might start by inputting a topic, a draft paragraph, or even a few keywords. The app could then generate a full article outline, suggest engaging headlines, draft paragraphs in various tones, and create relevant images or graphics to accompany the text. Users can refine outputs with simple prompts or edits, and receive instant AI-generated alternatives.\n",
    "\n",
    "The user interface should be clean, intuitive, and responsive. Features like real-time suggestions, drag-and-drop image placement, and easy content export options ensure that the application fits seamlessly into existing workflows. Contextual tooltips and onboarding guides can help new users understand how to leverage GenAI effectively, making advanced AI capabilities accessible even to those with minimal technical knowledge.\n",
    "\n",
    "Integration of Generative AI Technologies\n",
    "A critical aspect is how GenAI is embedded into the application. This involves selecting the appropriate models and technologies and ensuring their outputs are reliable, safe, and relevant.\n",
    "\n",
    "You might choose large language models (LLMs) such as GPT-4 for natural language understanding and generation tasks. These models excel at drafting coherent, creative text and summarizing complex information. For image creation, integration with models like DALL·E or Stable Diffusion could enable users to generate unique visuals on demand. Multimodal capabilities, combining text and images, offer richer, more engaging outputs.\n",
    "\n",
    "Behind the scenes, your app will call these models via APIs or run lightweight versions locally, depending on scalability and privacy requirements. Quality control mechanisms, such as filtering inappropriate content and detecting hallucinations (AI-generated inaccuracies), are essential to maintain trust. You might also implement user feedback loops where outputs can be rated or flagged, allowing continuous improvement.\n",
    "\n",
    "User Experience and Workflow\n",
    "A great application delivers a seamless, efficient, and engaging user experience from the moment someone opens it to the completion of their task.\n",
    "\n",
    "Users should be able to start with minimal input and be guided through a clear workflow that helps them leverage the AI’s capabilities fully. For example, after entering a basic prompt, the app might generate multiple suggestions, allow users to choose or combine them, and then polish the final output with AI-assisted editing tools.\n",
    "\n",
    "Smart defaults and contextual recommendations can anticipate user needs, reducing friction. Additionally, providing real-time previews of AI-generated content helps users quickly assess and iterate. By integrating features like autosave, version history, and collaboration tools, the application can support both solo and team workflows.\n",
    "\n",
    "Personalization and Context-Awareness\n",
    "One of the key strengths of GenAI is its ability to personalize content dynamically based on user preferences, past interactions, and context.\n",
    "\n",
    "Your application should collect relevant data—such as preferred writing style, tone, or frequently used vocabulary—and tailor AI outputs accordingly. For instance, it could switch between formal and casual language depending on the target audience or adjust image styles based on branding guidelines.\n",
    "\n",
    "Context-awareness also means the app understands the task at hand, the project stage, or even external factors like trending topics, thereby producing more relevant suggestions. Over time, the AI learns from user feedback and behavior, refining its recommendations and making interactions smoother and more productive.\n",
    "\n",
    "Ethical and Responsible AI Use\n",
    "Deploying GenAI responsibly is crucial. AI models can sometimes generate biased, inappropriate, or factually incorrect content (hallucinations), which can harm user trust and safety.\n",
    "\n",
    "Your application must include safeguards such as content moderation filters, transparency about AI limitations, and disclaimers where necessary. You might provide users with options to report issues or correct AI outputs. Embedding ethical guidelines into the design and offering users control over data privacy ensures compliance with regulations and builds long-term confidence.\n",
    "\n",
    "Regularly updating the AI models to reduce bias and improve accuracy, and being transparent about how the AI works, further enhances responsible use.\n",
    "\n",
    "Scalability and Future Enhancements\n",
    "Design your application with scalability and growth in mind. As AI technologies advance, new features and capabilities can be integrated to enhance value.\n",
    "\n",
    "Future versions might support additional languages to serve a global audience, incorporate audio or video generation for richer content formats, or use retrieval-augmented generation (RAG) techniques to ground AI outputs in verified external knowledge. Memory modules could allow the AI to remember past sessions, offering continuity and deeper personalization.\n",
    "\n",
    "Moreover, expanding to new domains or user types can broaden impact, while analytics dashboards might help users track productivity and creativity metrics. By planning for these enhancements early, your application stays relevant and competitive.\n",
    "\n",
    "Application Example: “CreatiGen — The AI-Powered Content Studio”\n",
    "To illustrate, imagine an app named CreatiGen, designed for content creators, marketers, and freelancers who want to supercharge their creative process.\n",
    "\n",
    "User Story:\n",
    "Sophia, a freelance writer, logs into CreatiGen to draft a blog post for a new client. She inputs the topic and a few key points. The AI instantly generates an outline, several headline options, and a draft introduction in a tone matching the client’s brand voice. Sophia tweaks the text with AI-powered grammar and style suggestions, then requests custom images to complement the article. The AI produces relevant, brand-consistent visuals. With everything integrated, Sophia exports a polished draft ready for client review—cutting her usual writing time by half.\n",
    "\n",
    "Why GenAI?\n",
    "Traditional writing tools provide static assistance—spell checks or templates—but CreatiGen’s GenAI models dynamically create personalized content tailored to user input and preferences. This dramatically reduces manual effort while boosting creativity and quality. The app’s multimodal approach, combining text and images, offers an integrated creative workflow unavailable in conventional tools.\n",
    "\n",
    "In conclusion, by thoughtfully designing a GenAI-powered application with clear purpose, user-centric features, seamless integration of AI models, ethical safeguards, and plans for future growth, you can create a transformative product. This application will not only solve real problems but also showcase the true potential of Generative AI to enhance human creativity, productivity, and decision-making in meaningful ways.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79913f55-5851-4943-9d71-094fb832912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest common contiguous phrase (8 words):\n",
      "'natural language processing (NLP), image generation, or multimodal'\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "result, length = longest_common_phrase(prompt1, prompt2)\n",
    "\n",
    "print(\"Longest common contiguous phrase ({} words):\".format(length))\n",
    "print(f\"'{result}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4df75-343a-4087-af52-6a1bdec326cf",
   "metadata": {},
   "source": [
    "### All Occurrences of the Longest Matching Phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318fd48d-c2e9-47ae-9093-d86ca33c65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_occurrences(phrase, prompt):\n",
    "    \"\"\"Returns list of indices where phrase occurs in prompt.\"\"\"\n",
    "    phrase_words = phrase.split()\n",
    "    prompt_words = prompt.split()\n",
    "    n = len(phrase_words)\n",
    "    return [\n",
    "        i for i in range(len(prompt_words)-n+1)\n",
    "        if prompt_words[i:i+n] == phrase_words\n",
    "    ]\n",
    "\n",
    "def longest_common_phrase(prompt1, prompt2):\n",
    "    # Same as before\n",
    "    words1 = prompt1.split()\n",
    "    words2 = prompt2.split()\n",
    "    len1, len2 = len(words1), len(words2)\n",
    "    dp = [[0]*(len2+1) for _ in range(len1+1)]\n",
    "    maxlen = 0\n",
    "    endpos1 = 0\n",
    "    endpos2 = 0\n",
    "\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            if words1[i] == words2[j]:\n",
    "                dp[i+1][j+1] = dp[i][j]+1\n",
    "                if dp[i+1][j+1] > maxlen:\n",
    "                    maxlen = dp[i+1][j+1]\n",
    "                    endpos1 = i+1\n",
    "                    endpos2 = j+1\n",
    "\n",
    "    if maxlen == 0:\n",
    "        return \"\", 0, [], []\n",
    "    phrase = ' '.join(words1[endpos1-maxlen:endpos1])\n",
    "    # Find all occurrences in both prompts\n",
    "    occ1 = find_all_occurrences(phrase, prompt1)\n",
    "    occ2 = find_all_occurrences(phrase, prompt2)\n",
    "    return phrase, maxlen, occ1, occ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b5de45-136c-447b-9967-d94a4ba51be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest phrase (8 words): 'natural language processing (NLP), image generation, or multimodal'\n",
      "Occurrences in Prompt 1: [23]\n",
      "Occurrences in Prompt 2: [47]\n"
     ]
    }
   ],
   "source": [
    "phrase, length, occ1, occ2 = longest_common_phrase(prompt1, prompt2)\n",
    "\n",
    "print(f\"Longest phrase ({length} words): '{phrase}'\")\n",
    "print(f\"Occurrences in Prompt 1: {occ1}\")\n",
    "print(f\"Occurrences in Prompt 2: {occ2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be41b44-21a2-40aa-9156-fee6d4282081",
   "metadata": {},
   "source": [
    "## All Matching Phrases of a Given Length or More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c34501c1-bcdc-41f0-babe-6ecedc90876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All common phrases of at least 6 words:\n",
      "- language processing (NLP), image generation, or multimodal\n",
      "- enhance human productivity, creativity, or decision-making.\n",
      "- natural language processing (NLP), image generation, or multimodal\n",
      "- natural language processing (NLP), image generation, or\n",
      "- text, images, summaries, answers, suggestions, or\n",
      "- natural language processing (NLP), image generation,\n",
      "- enhance human productivity, creativity, or decision-making. The\n",
      "- human productivity, creativity, or decision-making. The\n",
      "- language processing (NLP), image generation, or\n",
      "- processing (NLP), image generation, or multimodal\n"
     ]
    }
   ],
   "source": [
    "def all_matching_phrases(prompt1, prompt2, min_length=2):\n",
    "    words1 = prompt1.split()\n",
    "    words2 = prompt2.split()\n",
    "    set1 = set()\n",
    "    set2 = set()\n",
    "    n1, n2 = len(words1), len(words2)\n",
    "    # Build all n-grams for both\n",
    "    for L in range(min_length, min(n1, n2)+1):\n",
    "        for i in range(n1-L+1):\n",
    "            set1.add(tuple(words1[i:i+L]))\n",
    "        for j in range(n2-L+1):\n",
    "            set2.add(tuple(words2[j:j+L]))\n",
    "    # Intersect sets to find common sequences\n",
    "    common = set1 & set2\n",
    "    return [' '.join(words) for words in common]\n",
    "\n",
    "# Example usage:\n",
    "matches = all_matching_phrases(prompt1, prompt2, min_length=6)\n",
    "print(\"All common phrases of at least 6 words:\")\n",
    "for m in matches:\n",
    "    print(\"-\", m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90099a-9525-47e0-a04d-bfa6c92bb849",
   "metadata": {},
   "source": [
    "## All Common Phrases of Any Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a06c875-5f3a-4ec8-a2cd-5d71231a7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All common contiguous phrases (from longest to shortest):\n",
      "\n",
      "- natural language processing (NLP), image generation, or multimodal\n",
      "- enhance human productivity, creativity, or decision-making. The\n",
      "- language processing (NLP), image generation, or multimodal\n",
      "- natural language processing (NLP), image generation, or\n",
      "- enhance human productivity, creativity, or decision-making.\n",
      "- human productivity, creativity, or decision-making. The\n",
      "- language processing (NLP), image generation, or\n",
      "- natural language processing (NLP), image generation,\n",
      "- processing (NLP), image generation, or multimodal\n",
      "- text, images, summaries, answers, suggestions, or\n",
      "- (NLP), image generation, or multimodal\n",
      "- enhance human productivity, creativity, or\n",
      "- human productivity, creativity, or decision-making.\n",
      "- images, summaries, answers, suggestions, or\n",
      "- language processing (NLP), image generation,\n",
      "- models like DALL·E or Stable\n",
      "- natural language processing (NLP), image\n",
      "- processing (NLP), image generation, or\n",
      "- productivity, creativity, or decision-making. The\n",
      "- text, images, summaries, answers, suggestions,\n",
      "- (NLP), image generation, or\n",
      "- Ethical and Responsible AI\n",
      "- Generative AI (GenAI) technologies\n",
      "- What specific problem does\n",
      "- creativity, or decision-making. The\n",
      "- enhance human productivity, creativity,\n",
      "- how GenAI is embedded\n",
      "- human productivity, creativity, or\n",
      "- image generation, or multimodal\n",
      "- images, summaries, answers, suggestions,\n",
      "- language processing (NLP), image\n",
      "- large language models (LLMs)\n",
      "- like DALL·E or Stable\n",
      "- models like DALL·E or\n",
      "- natural language processing (NLP),\n",
      "- processing (NLP), image generation,\n",
      "- productivity, creativity, or decision-making.\n",
      "- summaries, answers, suggestions, or\n",
      "- text, images, summaries, answers,\n",
      "- the core features and\n",
      "- (NLP), image generation,\n",
      "- AI (GenAI) technologies\n",
      "- DALL·E or Stable\n",
      "- Ethical and Responsible\n",
      "- GenAI into a\n",
      "- GenAI is embedded\n",
      "- Generative AI (GenAI)\n",
      "- Purpose and Use\n",
      "- Scalability and Future\n",
      "- User Experience and\n",
      "- What specific problem\n",
      "- Your application should\n",
      "- about how the\n",
      "- and Responsible AI\n",
      "- answers, suggestions, or\n",
      "- application must include\n",
      "- based on user\n",
      "- core features and\n",
      "- creativity, or decision-making.\n",
      "- enhance human productivity,\n",
      "- from start to\n",
      "- generation, or multimodal\n",
      "- how GenAI is\n",
      "- human productivity, creativity,\n",
      "- image generation, or\n",
      "- images, summaries, answers,\n",
      "- language models (LLMs)\n",
      "- language processing (NLP),\n",
      "- large language models\n",
      "- like DALL·E or\n",
      "- models like DALL·E\n",
      "- natural language processing\n",
      "- or decision-making. The\n",
      "- processing (NLP), image\n",
      "- productivity, creativity, or\n",
      "- retrieval-augmented generation (RAG)\n",
      "- seamless, efficient, and\n",
      "- specific problem does\n",
      "- strengths of GenAI\n",
      "- summaries, answers, suggestions,\n",
      "- text, images, summaries,\n",
      "- the core features\n",
      "- to enhance human\n",
      "- — such as\n",
      "- (GenAI) technologies\n",
      "- (NLP), image\n",
      "- AI (GenAI)\n",
      "- DALL·E or\n",
      "- Ethical and\n",
      "- Experience and\n",
      "- GenAI into\n",
      "- GenAI is\n",
      "- Generative AI\n",
      "- Personalization and\n",
      "- Purpose and\n",
      "- Responsible AI\n",
      "- Scalability and\n",
      "- User Experience\n",
      "- What specific\n",
      "- Your application\n",
      "- a clear\n",
      "- a full\n",
      "- about how\n",
      "- adapt to\n",
      "- and Future\n",
      "- and Responsible\n",
      "- and Use\n",
      "- and a\n",
      "- and context-aware\n",
      "- answers, suggestions,\n",
      "- application must\n",
      "- application should\n",
      "- application that\n",
      "- based on\n",
      "- by integrating\n",
      "- capabilities accessible\n",
      "- core features\n",
      "- creativity, or\n",
      "- decision-making. The\n",
      "- define the\n",
      "- does the\n",
      "- efficient, and\n",
      "- enhance human\n",
      "- features and\n",
      "- formats, or\n",
      "- from start\n",
      "- generation (RAG)\n",
      "- generation, or\n",
      "- how GenAI\n",
      "- how the\n",
      "- human productivity,\n",
      "- image generation,\n",
      "- images, summaries,\n",
      "- input and\n",
      "- into a\n",
      "- is embedded\n",
      "- language models\n",
      "- language processing\n",
      "- large language\n",
      "- like DALL·E\n",
      "- models (LLMs)\n",
      "- models and\n",
      "- models like\n",
      "- must include\n",
      "- natural language\n",
      "- of GenAI\n",
      "- of GenAI?\n",
      "- of the\n",
      "- on user\n",
      "- or Stable\n",
      "- or decision-making.\n",
      "- or multimodal\n",
      "- outputs are\n",
      "- problem does\n",
      "- processing (NLP),\n",
      "- productivity, creativity,\n",
      "- retrieval-augmented generation\n",
      "- seamless, efficient,\n",
      "- specific problem\n",
      "- start to\n",
      "- strengths of\n",
      "- such as\n",
      "- suggestions, or\n",
      "- summaries, answers,\n",
      "- target audience\n",
      "- text, images,\n",
      "- the app\n",
      "- the application.\n",
      "- the core\n",
      "- to enhance\n",
      "- traditional software\n",
      "- user interface\n",
      "- users to\n",
      "- with the\n",
      "- — such\n",
      "- (GenAI)\n",
      "- (LLMs)\n",
      "- (NLP),\n",
      "- (RAG)\n",
      "- AI\n",
      "- AI-powered\n",
      "- APIs\n",
      "- DALL·E\n",
      "- Design\n",
      "- Ethical\n",
      "- Experience\n",
      "- Future\n",
      "- GenAI\n",
      "- GenAI?\n",
      "- Generative\n",
      "- How\n",
      "- Key\n",
      "- Personalization\n",
      "- Purpose\n",
      "- Responsible\n",
      "- Scalability\n",
      "- Stable\n",
      "- The\n",
      "- Use\n",
      "- User\n",
      "- What\n",
      "- You\n",
      "- Your\n",
      "- a\n",
      "- about\n",
      "- accessible\n",
      "- adapt\n",
      "- additional\n",
      "- an\n",
      "- and\n",
      "- answers,\n",
      "- app\n",
      "- application\n",
      "- application,\n",
      "- application.\n",
      "- are\n",
      "- as\n",
      "- audience\n",
      "- based\n",
      "- be\n",
      "- beyond\n",
      "- both\n",
      "- by\n",
      "- can\n",
      "- capabilities\n",
      "- choose\n",
      "- clear\n",
      "- compelling\n",
      "- content\n",
      "- context-aware\n",
      "- core\n",
      "- creation,\n",
      "- creativity,\n",
      "- decision-making.\n",
      "- define\n",
      "- designed\n",
      "- does\n",
      "- efficient,\n",
      "- embedded\n",
      "- enhance\n",
      "- ensure\n",
      "- experience\n",
      "- experiences.\n",
      "- features\n",
      "- feedback\n",
      "- for\n",
      "- formats,\n",
      "- from\n",
      "- full\n",
      "- future\n",
      "- generating\n",
      "- generation\n",
      "- generation,\n",
      "- have\n",
      "- how\n",
      "- human\n",
      "- human-like\n",
      "- image\n",
      "- images,\n",
      "- in\n",
      "- include\n",
      "- incorporate\n",
      "- input\n",
      "- integrating\n",
      "- interactions\n",
      "- interface\n",
      "- into\n",
      "- is\n",
      "- it\n",
      "- its\n",
      "- language\n",
      "- large\n",
      "- like\n",
      "- make\n",
      "- models\n",
      "- more\n",
      "- multimodal\n",
      "- must\n",
      "- natural\n",
      "- novel\n",
      "- of\n",
      "- offer\n",
      "- on\n",
      "- or\n",
      "- outputs\n",
      "- outputs.\n",
      "- over\n",
      "- personalized\n",
      "- potential\n",
      "- preferences,\n",
      "- problem\n",
      "- processing\n",
      "- productivity,\n",
      "- provide\n",
      "- real-world\n",
      "- retrieval-augmented\n",
      "- seamless,\n",
      "- should\n",
      "- significantly\n",
      "- simple\n",
      "- software\n",
      "- solve?\n",
      "- specific\n",
      "- start\n",
      "- strengths\n",
      "- such\n",
      "- suggestions,\n",
      "- summaries,\n",
      "- support\n",
      "- target\n",
      "- technologies\n",
      "- text\n",
      "- text,\n",
      "- that\n",
      "- the\n",
      "- to\n",
      "- tones,\n",
      "- traditional\n",
      "- types\n",
      "- understanding\n",
      "- use\n",
      "- user\n",
      "- users\n",
      "- while\n",
      "- will\n",
      "- with\n",
      "- you\n",
      "- your\n",
      "- —\n"
     ]
    }
   ],
   "source": [
    "def all_common_phrases_any_length(prompt1, prompt2):\n",
    "    words1 = prompt1.split()\n",
    "    words2 = prompt2.split()\n",
    "    n1, n2 = len(words1), len(words2)\n",
    "    common_phrases = set()\n",
    "    \n",
    "    # Build a lookup for words2 for fast matching\n",
    "    for length in range(1, min(n1, n2) + 1):\n",
    "        # All n-grams in prompt1\n",
    "        ngrams1 = set(tuple(words1[i:i+length]) for i in range(n1 - length + 1))\n",
    "        # All n-grams in prompt2\n",
    "        ngrams2 = set(tuple(words2[j:j+length]) for j in range(n2 - length + 1))\n",
    "        # Intersection gives common phrases of this length\n",
    "        for phrase in ngrams1 & ngrams2:\n",
    "            common_phrases.add(' '.join(phrase))\n",
    "    return sorted(common_phrases, key=lambda x: (-len(x.split()), x))\n",
    "\n",
    "\n",
    "matches = all_common_phrases_any_length(prompt1, prompt2)\n",
    "\n",
    "print(\"All common contiguous phrases (from longest to shortest):\\n\")\n",
    "for phrase in matches:\n",
    "    print(f\"- {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8860f357-24b8-4a1a-afa1-533915f69fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- neural networks mimic the human brain to some extent\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def all_max_common_phrases(prompt1, prompt2, min_length=3):\n",
    "    words1 = prompt1.split()\n",
    "    words2 = prompt2.split()\n",
    "    matcher = SequenceMatcher(None, words1, words2, autojunk=False)\n",
    "    matches = []\n",
    "    for match in matcher.get_matching_blocks():\n",
    "        if match.size >= min_length:\n",
    "            phrase = ' '.join(words1[match.a:match.a + match.size])\n",
    "            matches.append(phrase)\n",
    "    # Remove duplicates, sort by length descending\n",
    "    return sorted(set(matches), key=lambda x: -len(x.split()))\n",
    "\n",
    "# ----- Example usage -----\n",
    "# Use realistic sample data for best performance demonstration\n",
    "prompt1 = \" \".join([\"neural networks mimic the human brain to some extent\"] * 1000)\n",
    "prompt2 = \" \".join([\"deep learning is important\", \"neural networks mimic the human brain to some extent\"] * 1000)\n",
    "\n",
    "matches = all_max_common_phrases(prompt1, prompt2, min_length=5)\n",
    "for phrase in matches:\n",
    "    print(\"-\", phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a602dbe-655c-41bd-ac0c-6ba2d6cb8c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
